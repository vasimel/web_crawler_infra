Terraform code for creating Web Crawler infrastructure

## Архитектура веб-сканера:
- Облачная сеть и подсеть: Внутренние ресурсы связаны через облачную сеть с подсетью для безопасного и быстрого доступа.
- Вычислительный ресурс: Виртуальная машина для добавления URL страниц в очередь Redis
- Вычислительный ресурс: 2 виртуальные машины с нужной конфигурацией для запуска обработчиков URL из очереди. После развертывания запускается scrapy-паук
- **https://github.com/vasimel/bookspider**
- Кластер Redis (1 узел) для очереди задач для краулера
- Кластер СУБД (содержит 2 узла): Реляционная база данных для хранения данных веб-сканера (структурированная информация с веб-страниц).
- Сервисный аккаунт: Сервисный аккаунт с ролями для доступа к Yandex Object Storage и мониторингу.
- Объектное хранилище (бакет): Хранилище для временного хранения больших данных, таких как HTML-контент или необработанные файлы, а также данных веб-сканера
